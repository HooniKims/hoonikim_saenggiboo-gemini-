# Ollama ë¡œì»¬ LLM ì—°ë™ ê°€ì´ë“œ (ìµœì¢… í™•ì •íŒ)

ì´ ë¬¸ì„œëŠ” Next.js(Netlify ë°°í¬) í”„ë¡œì íŠ¸ì—ì„œ Ollama ë¡œì»¬ LLMì„ `api.alluser.site` í”„ë¡ì‹œë¥¼ í†µí•´ ì‚¬ìš©í•˜ëŠ” ìµœì¢… ì—°ë™ ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ì•„í‚¤í…ì²˜ (ìµœì¢…)

```
[ì‚¬ìš©ì ë¸Œë¼ìš°ì € (í•œêµ­)] â”€â”€ì§ì ‘ í˜¸ì¶œâ”€â”€â–¶ [api.alluser.site (Nginx í”„ë¡ì‹œ)] â”€â”€â–¶ [Ollama (192.168.0.182:11434)]
```

### âš ï¸ ì™œ ì„œë²„ë¦¬ìŠ¤ í”„ë¡ì‹œë¥¼ ì“°ì§€ ì•ŠëŠ”ê°€?

Netlify ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ëŠ” **í•´ì™¸ ì„œë²„(ë¯¸êµ­/ìœ ëŸ½)**ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
`api.alluser.site`ëŠ” í•œêµ­ ê°€ì • ë„¤íŠ¸ì›Œí¬ì— ìˆì–´ í•´ì™¸ì—ì„œì˜ ì—°ê²°ì´ **ë°©í™”ë²½/ISPì— ì˜í•´ ì°¨ë‹¨**ë©ë‹ˆë‹¤.
ë”°ë¼ì„œ **ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ APIë¥¼ í˜¸ì¶œ**í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì‹œë„í–ˆì§€ë§Œ ì‹¤íŒ¨í•œ ë°©ë²•ë“¤:
- âŒ `runtime = "edge"` â†’ Edge í•¨ìˆ˜ì—ì„œ OpenAI SDK í˜¸í™˜ ë¬¸ì œ (502)
- âŒ `runtime = "nodejs"` â†’ Netlify ì„œë²„ â†’ api.alluser.site ì—°ê²° íƒ€ì„ì•„ì›ƒ (ConnectTimeoutError)
- âŒ ìŠ¤íŠ¸ë¦¬ë° + ì„œë²„ë¦¬ìŠ¤ â†’ Netlify 10ì´ˆ í•˜ë“œ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ 504 ë°œìƒ

---

## 1. Nginx ì„¤ì • (api.alluser.site)

```nginx
location / {
    # ===== CORS ì„¤ì • =====
    set $cors_origin "";
    if ($http_origin = "https://hoonikim-saenggibu.netlify.app") { set $cors_origin $http_origin; }
    if ($http_origin = "http://localhost:3000") { set $cors_origin $http_origin; }

    if ($request_method = OPTIONS) {
        add_header 'Access-Control-Allow-Origin' $cors_origin always;
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS' always;
        add_header 'Access-Control-Allow-Headers' 'Content-Type, X-API-Key' always;
        add_header 'Access-Control-Max-Age' 86400 always;
        add_header 'Content-Length' 0;
        return 204;
    }

    add_header 'Access-Control-Allow-Origin' $cors_origin always;

    # ===== API Key ì¸ì¦ =====
    if ($http_x_api_key != "gudgns0411skaluv2018tjdbs130429") {
        return 401 '{"error":"Unauthorized"}';
    }

    # ===== Proxy to Ollama =====
    proxy_pass http://192.168.0.182:11434;

    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # ===== Ollama ê¸°ë³¸ CORS í—¤ë” ì œê±° (ì¶©ëŒ ë°©ì§€) =====
    proxy_hide_header 'Access-Control-Allow-Origin';
    proxy_hide_header 'Access-Control-Allow-Methods';
    proxy_hide_header 'Access-Control-Allow-Headers';

    # ===== Streaming / ì„±ëŠ¥ ìµœì í™” =====
    proxy_buffering off;
    proxy_request_buffering off;
    proxy_cache off;
    add_header X-Accel-Buffering no;

    proxy_http_version 1.1;
    proxy_set_header Connection "";

    # ===== íƒ€ì„ì•„ì›ƒ =====
    proxy_read_timeout 600s;
    proxy_connect_timeout 30s;
    proxy_send_timeout 600s;

    gzip off;
}
```

### ë‹¤ë¥¸ í”„ë¡œì íŠ¸ ì¶”ê°€ ì‹œ
`if ($http_origin = "https://ìƒˆë„ë©”ì¸.netlify.app") { set $cors_origin $http_origin; }` í•œ ì¤„ë§Œ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤.

---

## 2. í´ë¼ì´ì–¸íŠ¸ ì½”ë“œ (`utils/streamFetch.js`)

ë¸Œë¼ìš°ì €ì—ì„œ Ollama APIë¥¼ **ì§ì ‘** í˜¸ì¶œí•©ë‹ˆë‹¤. ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ë¥¼ ê±°ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

```javascript
const OLLAMA_API_URL = "https://api.alluser.site";
const OLLAMA_API_KEY = "gudgns0411skaluv2018tjdbs130429";

export async function fetchStream(bodyData) {
    const { prompt, additionalInstructions } = bodyData;

    let systemMessage = "ì„ ìƒë‹˜ì„ ë•ëŠ” ì „ë¬¸ê°€ë¡œì„œ í•™ìƒë“¤ì˜ í•™êµìƒí™œê¸°ë¡ë¶€ ì‘ì„±ì„ ë„ì™€ì¤ë‹ˆë‹¤.";
    if (additionalInstructions) {
        systemMessage += `\n\nã€ğŸš¨ ìµœìš°ì„  ì§€ì¹¨ã€‘\n${additionalInstructions}`;
    }

    const res = await fetch(`${OLLAMA_API_URL}/v1/chat/completions`, {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
            "X-API-Key": OLLAMA_API_KEY,
        },
        body: JSON.stringify({
            model: "gemma3:12b-it-q4_K_M",
            messages: [
                { role: "system", content: systemMessage },
                { role: "user", content: prompt },
            ],
            temperature: 0.7,
            stream: false,
        }),
    });

    if (!res.ok) {
        let errorMessage = `ì„œë²„ ì˜¤ë¥˜ (${res.status})`;
        try {
            const errorData = await res.json();
            errorMessage = errorData.error || errorMessage;
        } catch {}
        throw new Error(errorMessage);
    }

    const data = await res.json();
    const content = data.choices?.[0]?.message?.content || "";
    if (!content.trim()) throw new Error("AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
    return content;
}
```

### í•µì‹¬ í¬ì¸íŠ¸
- **OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸** (`/v1/chat/completions`) ì‚¬ìš© â†’ `messages` ë°°ì—´ ì§€ì›
- **`X-API-Key` í—¤ë”**ë¡œ ì¸ì¦ (Nginxì—ì„œ í™•ì¸)
- **`stream: false`** â†’ ë¹„ìŠ¤íŠ¸ë¦¬ë° (ì•ˆì •ì„± ìš°ì„ )

---

## 3. ê° í˜ì´ì§€ì—ì„œì˜ ì‚¬ìš©ë²•

4ê°œ í˜ì´ì§€(gwasetuk, club, behavior, letter)ì—ì„œ `fetchStream`ì„ importí•˜ì—¬ ì‚¬ìš©:

```javascript
import { fetchStream } from "../../utils/streamFetch";

// ì‚¬ìš© ì˜ˆì‹œ
const rawResult = await fetchStream({ prompt, additionalInstructions });
```

ê° í˜ì´ì§€ëŠ” ì„œë²„ API ë¼ìš°íŠ¸(`/api/generate`)ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³ , `fetchStream`ì´ ì§ì ‘ `api.alluser.site`ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

---

## 4. Ollama ì„œë²„ ê´€ë¦¬ (Mac mini)

### ëª¨ë¸ ì˜ˆì—´ (í•„ìˆ˜)
```bash
# ëª¨ë¸ì„ 24ì‹œê°„ ë™ì•ˆ ë©”ëª¨ë¦¬ì— ìœ ì§€
ollama run gemma3:12b-it-q4_K_M "ì•ˆë…•" --keepalive 24h
```

### ëª¨ë¸ ìƒíƒœ í™•ì¸
```bash
ollama ps        # í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ í™•ì¸
ollama list      # ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡
```

### ëª¨ë¸ ìƒì‹œ ìœ ì§€ (cron ìë™í™”)
```bash
# crontab -e ë¡œ ì¶”ê°€ â†’ 4ë¶„ë§ˆë‹¤ pingí•˜ì—¬ ëª¨ë¸ ìœ ì§€
*/4 * * * * curl -s http://localhost:11434/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"gemma3:12b-it-q4_K_M","messages":[{"role":"user","content":"ping"}]}' \
  > /dev/null 2>&1
```

---

## 5. í™˜ê²½ ë³€ìˆ˜ (.env)

ë¡œì»¬ ê°œë°œìš© `.env` íŒŒì¼ (ë°°í¬ ì‹œì—ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ):
```env
OLLAMA_API_URL=https://api.alluser.site
OLLAMA_API_KEY=gudgns0411skaluv2018tjdbs130429
```

> âš ï¸ í˜„ì¬ ë¸Œë¼ìš°ì € ì§ì ‘ í˜¸ì¶œ ë°©ì‹ì´ë¯€ë¡œ Netlify í™˜ê²½ ë³€ìˆ˜ëŠ” ì‚¬ì‹¤ìƒ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.
> API í‚¤ì™€ URLì€ `utils/streamFetch.js`ì— ì§ì ‘ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## 6. ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

ë¬¸ì œ ë°œìƒ ì‹œ ìˆœì„œëŒ€ë¡œ í™•ì¸:

| ìˆœì„œ | í™•ì¸ ì‚¬í•­ | ëª…ë ¹ì–´ |
|------|-----------|--------|
| 1 | Ollama ì‹¤í–‰ ì¤‘? | `ollama ps` |
| 2 | ëª¨ë¸ ë¡œë“œë¨? | `ollama ps` (ëª¨ë¸ëª… í‘œì‹œ í™•ì¸) |
| 3 | ë¡œì»¬ API ì‘ë‹µ? | `curl http://localhost:11434/v1/chat/completions -H "Content-Type: application/json" -d '{"model":"llama3.1:8b","messages":[{"role":"user","content":"hi"}]}'` |
| 4 | í”„ë¡ì‹œ ê²½ìœ  ì‘ë‹µ? | `curl https://api.alluser.site/v1/chat/completions -H "Content-Type: application/json" -H "X-API-Key: gudgns0411skaluv2018tjdbs130429" -d '{"model":"llama3.1:8b","messages":[{"role":"user","content":"hi"}]}'` |
| 5 | Nginx ìƒíƒœ? | `sudo nginx -t` |
| 6 | CORS ì—ëŸ¬? | ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ `Access-Control-Allow-Origin` ê´€ë ¨ ì—ëŸ¬ í™•ì¸ |
| 7 | ëª¨ë¸ cold start? | `ollama run llama3.1:8b "test" --keepalive 24h` |
