# Ollama ë¡œì»¬ LLM ì—°ë™ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” Next.js í”„ë¡œì íŠ¸ì—ì„œ Ollama(ë˜ëŠ” OpenAI í˜¸í™˜ API ì„œë¹„ìŠ¤)ë¥¼ ì—°ë™í•˜ì—¬ ë¡œì»¬ LLM(`llama3.1:8b`)ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (`.env`)

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ `.env` íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

```env
# ë¡œì»¬ LLM ë˜ëŠ” Ollama API ì£¼ì†Œ ë° í‚¤
OLLAMA_API_URL=https://api.alluser.site
OLLAMA_API_KEY=your_api_key_here
```

## 2. API ë¼ìš°íŠ¸ êµ¬í˜„ (`app/api/generate/route.js`)

`openai` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜, `baseURL`ê³¼ `defaultHeaders`ë¥¼ ì¡°ì •í•˜ì—¬ Ollama(ë˜ëŠ” í”„ë¡ì‹œ ì„œë²„)ì™€ í†µì‹ í•©ë‹ˆë‹¤.

```javascript
import { NextResponse } from 'next/server';
import OpenAI from 'openai';

export async function POST(req) {
    try {
        const body = await req.json();
        const { prompt, additionalInstructions } = body;

        // 1. Ollama ì„¤ì • í™•ì¸
        const ollamaUrl = process.env.OLLAMA_API_URL;
        const ollamaKey = process.env.OLLAMA_API_KEY;

        let clientSettings = {};
        let model = "";

        if (ollamaUrl) {
            // Ollama / ë¡œì»¬ LLM ëª¨ë“œ
            clientSettings = {
                apiKey: ollamaKey || 'ollama',
                baseURL: `${ollamaUrl}/v1`,
                // íŠ¹ì • í”„ë¡ì‹œëŠ” Authorization ëŒ€ì‹  x-api-keyë¥¼ ìš”êµ¬í•  ìˆ˜ ìˆìŒ
                defaultHeaders: {
                    'x-api-key': ollamaKey 
                }
            };
            model = "llama3.1:8b";
            console.log(`[API] Ollama ëª¨ë“œ ì‚¬ìš©: ${ollamaUrl}, ëª¨ë¸: ${model}`);
        } else {
            // OpenAI ëª¨ë“œ (Fallback)
            clientSettings = { apiKey: process.env.OPENAI_API_KEY };
            const hasAdditionalInstructions = additionalInstructions && additionalInstructions.trim();
            model = hasAdditionalInstructions ? "gpt-4o" : "gpt-4o-mini";
        }

        const openai = new OpenAI(clientSettings);

        // 2. ë©”ì‹œì§€ êµ¬ì„±
        let systemMessage = "ì„ ìƒë‹˜ì„ ë•ëŠ” ì „ë¬¸ê°€ë¡œì„œ í•™ìƒë“¤ì˜ í•™êµìƒí™œê¸°ë¡ë¶€ ì‘ì„±ì„ ë„ì™€ì¤ë‹ˆë‹¤.";
        if (additionalInstructions) {
            systemMessage += `\n\nã€ğŸš¨ ìµœìš°ì„  ì§€ì¹¨ã€‘\n${additionalInstructions}`;
        }

        // 3. ìƒì„± ìš”ì²­
        const completion = await openai.chat.completions.create({
            model: model,
            messages: [
                { role: "system", content: systemMessage },
                { role: "user", content: prompt },
            ],
            temperature: 0.7,
        });

        const content = completion.choices[0].message.content;
        return NextResponse.json({ result: content });

    } catch (error) {
        console.error("API Error:", error);
        return NextResponse.json(
            { error: error.message || "ìƒì„± ì‹¤íŒ¨" },
            { status: 500 }
        );
    }
}
```

## 3. í•µì‹¬ ì²´í¬í¬ì¸íŠ¸

-   **OpenAI SDK í˜¸í™˜ì„±**: OllamaëŠ” `/v1` ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ OpenAI ê·œê²©ì„ ì§€ì›í•˜ë¯€ë¡œ `baseURL: "${URL}/v1"`ë¡œ ì„¤ì •í•˜ë©´ ê¸°ì¡´ ì½”ë“œë¥¼ ê±°ì˜ ê·¸ëŒ€ë¡œ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
-   **Header íƒìƒ‰**: ì¼ë¶€ ë³´ì•ˆ í”„ë¡ì‹œ ì„œë²„(ì˜ˆ: `api.alluser.site`)ëŠ” í‘œì¤€ `Authorization: Bearer` ëŒ€ì‹  `x-api-key` í—¤ë”ë¥¼ ìš”êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `defaultHeaders` ì˜µì…˜ì„ í™œìš©í•˜ì—¬ í•´ê²°í–ˆìŠµë‹ˆë‹¤.
-   **ë™ì  ëª¨ë¸ ì„ íƒ**: `OLLAMA_API_URL` ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¼ ë¡œì»¬ LLM(`llama3.1:8b`)ê³¼ OpenAI ëª¨ë¸ ì‚¬ì´ë¥¼ ìœ ì—°í•˜ê²Œ ìŠ¤ìœ„ì¹­í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.
